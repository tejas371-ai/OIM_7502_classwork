{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a40e3439-6b76-4709-8a2a-d0670432b88d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# PyCaret End-to-End Workflow\n",
    "\n",
    "The most valuable feature of PyCaret is its highly consistent, low-code API across different machine learning tasks. This structure allows a data scientist to rapidly switch between problems (supervised, unsupervised, time series) while maintaining a standard workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b460c5d-ebcd-4e9b-8659-7111ece449e3",
   "metadata": {},
   "source": [
    "## 1. Supervised Learning: Classification & Regression\n",
    "\n",
    "This workflow is used for predictive modeling and includes critical steps like automated model comparison and hyperparameter optimization.\n",
    "\n",
    "| Step | PyCaret Function | Purpose / Data Scientist Value |\n",
    "| :--- | :--- | :--- |\n",
    "| **Import Libraries** | `from pycaret.[module] import *` | Imports the specific module (`.classification` or `.regression`). |\n",
    "| **Load Dataset** | `get_data('data_name')` | Loads built-in data or a custom Pandas DataFrame. |\n",
    "| **Setup Experiment** | `setup(data, target='col', ...)` | **Automated Preprocessing** (Imputation, Scaling, Encoding, Splitting). |\n",
    "| **Compare Models** | `compare_models()` | **Benchmarking:** Trains and ranks all available models. |\n",
    "| **Tune the Model** | `tune_model(best_model)` | **Optimization:** Automatically searches for optimal hyperparameters. |\n",
    "| **Plot Diagnostics** | `plot_model(tuned_model, plot='auc/feature')` | **Explainability:** Visualizes performance and feature importance. |\n",
    "| **Evaluate Model** | `evaluate_model(final_model)` | Launches an **Interactive Dashboard** for detailed performance analysis. |\n",
    "| **Finalize Model** | `finalize_model(model)` | Retrains the model on the full dataset for final use. |\n",
    "| **Save Model** | `save_model(final_model, 'pipeline_name')` | **MLOps:** Saves the complete pipeline (preprocessing + model) for deployment. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1e11db-5a9d-4931-9d01-de0383fdf141",
   "metadata": {},
   "source": [
    "## 2. Time Series (Forecasting)\n",
    "\n",
    "Used for predicting a continuous value over time, defining the length of the prediction period.\n",
    "\n",
    "| Step | PyCaret Function | Purpose / Data Scientist Value |\n",
    "| :--- | :--- | :--- |\n",
    "| **Import Libraries** | `from pycaret.time_series import *` | Imports the specialized forecasting module. |\n",
    "| **Load Dataset** | `get_data('airline')` | Time series data with a date index. |\n",
    "| **Setup Experiment** | `setup(data, target='col', fh=12, ...)` | Defines the **forecast horizon (`fh`)** and sets up time-series specific cross-validation. |\n",
    "| **Compare Models** | `compare_models()` | Evaluates various forecasting algorithms. |\n",
    "| **Plot Forecast** | `plot_model(model, plot='forecast')` | Visualizes the predicted future time window. |\n",
    "| **Finalize & Save** | `finalize_model(model)` / `save_model(...)` | Finalizes the model and saves the pipeline. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0586e9-2088-4701-a0cd-3d8a46e80def",
   "metadata": {},
   "source": [
    "## 3. Unsupervised Learning: Clustering & Anomaly Detection\n",
    "\n",
    "These modules are used for discovery and inspection rather than prediction (no `target` variable is used in the setup).\n",
    "\n",
    "### Clustering Workflow\n",
    "\n",
    "| Step | PyCaret Function | Purpose / Data Scientist Value |\n",
    "| :--- | :--- | :--- |\n",
    "| **Import Libraries** | `from pycaret.clustering import *` | Imports the clustering module. |\n",
    "| **Load Dataset** | `get_data('jewellery')` | Data for customer segmentation or grouping. |\n",
    "| **Setup Experiment** | `setup(data, ...)` | Initializes environment (no `target` specified). |\n",
    "| **Create Model** | `create_model('kmeans', num_clusters=4)` | Trains a specific model and defines the number of segments. |\n",
    "| **Assign Model** | `assign_model(model)` | Adds the new **Cluster Labels** (e.g., 'Segment A', 'Segment B') to the original dataset. |\n",
    "| **Plot Model** | `plot_model(model, plot='cluster')` | Visualizes the resulting clusters. |\n",
    "| **Save Model** | `save_model(model, 'clustering_pipeline')` | Saves the model for consistently classifying new data points. |\n",
    "\n",
    "### Anomaly Detection Workflow\n",
    "\n",
    "| Step | PyCaret Function | Purpose / Data Scientist Value |\n",
    "| :--- | :--- | :--- |\n",
    "| **Import Libraries** | `from pycaret.anomaly import *` | Imports the anomaly detection module. |\n",
    "| **Load Dataset** | `get_data('kiva')` | Data for outlier identification (e.g., fraud). |\n",
    "| **Setup Experiment** | `setup(data, ...)` | Initializes environment (no `target` specified). |\n",
    "| **Create Model** | `create_model('iforest')` | Trains a specific anomaly detection algorithm (e.g., Isolation Forest). |\n",
    "| **Assign Model** | `assign_model(model)` | Adds the **Anomaly Label (`1/0`)** and **Anomaly Score** to the dataset. |\n",
    "| **Predict & Filter** | `data[data['Anomaly'] == 1]` | **Analysis:** Filters the dataset to isolate and analyze the identified outliers. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35027d-baf8-401a-97e4-dfbadc28ede9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
